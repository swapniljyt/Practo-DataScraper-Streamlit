# Practo-DataScraper-Streamlit
## Project Title
Practo-DataScraper-Streamlit
## Project Description
The Practo-DataScraper-Streamlit application allows users to scrape doctor profiles from Practo.com based on a specified location and specialization. The application, built using Streamlit, provides an input box for the user to enter the city and a dropdown menu to select the doctor's specialization. After scraping, the application generates a CSV file containing details such as the doctor's name, specialization, experience, and practice locality.
This project demonstrates the use of web scraping with BeautifulSoup and data presentation using Streamlit.The required python version for this app is 3.10.13.
## Installation Instructions
1. **Clone the Repository:**
   ```bash
   git clone <repository_url>
2. **Navigate to the Project Directory:**
      ```bash
   cd Practo-DataScraper-Streamlit>
3. **Initialize Git:**
   ```bash
   git init
   git config --global user.name "your_user_name"
   git config --global user.email "your_email">
4. **Set Up Conda Environment:**
   ```bash
   conda init
   conda create -n env_name python=3.10.13 -y
   source activate env_name>
5. **Install Required Libraries:**
   - Libraries we need to install:
     - **pandas**: For handling and manipulating data, especially to create the CSV file.
     - **Streamlit**: For creating the web application interface.
     - **beautifulsoup4**: For parsing and scraping the HTML content.
     - **ipykernel**: Required for running Python kernels, especially when using Jupyter Notebooks.
     - **Requests**: For sending HTTP requests to Practo.com and retrieving web pages.

   - All these libraries have already been mentioned in the `requirements.txt` file. You can install them by running the following command:

   ```bash
   pip install -r requirements.txt

6. **Verify Installation:**
   ```bash
   pip list>

# Usage

1. **Run the Streamlit Application:**
   ```bash
   streamlit run App.py>

2. **Access the Application:**
- After run the command on terminal you will get something like this
- Copy the url in Browser
  - Local URL: http://localhost:8503
  - Network URL: http://172.19.2.2:8503
  - External URL: http://34.82.65.223:8503
3. **Interact with the Application:**
  - Copy the url in Browser
    - *Doctor Location City*: An input box where you can enter the city name. Ensure that the city name is spelled correctly and is a legal city.
    - *Select a Specialization*: A dropdown menu allows you to choose the doctor's specialization from a list of options including Cardiologist, Dentist, Dermatologist, Gynecologist, and more
4. **Start Scraping:**
  After entering the location and selecting a specialization, click the "Scrape" button to initiate the web scraping process. The application will start collecting data from Practo.com based on the given inputs.

5. **Output**
 -Upon completion of the scraping process, the application will generate a downloadable CSV file containing the following columns:
   -Doctor Name: The name of the doctor.
   -Specialization: The medical specialization of the doctor.
   -Experience: The number of years of experience the doctor has.
   -Practice Locality: The area or locality where the doctor practices.
-The CSV file will be available for download directly from the application interface.

# Output
 CSV File: The CSV file generated by the application contains the collected doctor profiles based on the specified location and specialization.
 The file includes the following columns: Doctor Name, Specialization, Experience, and Practice Locality. 
 This file can be used for further analysis or reference.

   

